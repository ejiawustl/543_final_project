{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7f4c929a-830a-4b6e-8cca-ebcaa5954add",
   "metadata": {},
   "source": [
    "# Evaluating Model Performance for Predicting 30-Day Hospital Readmissions\n",
    "\n",
    "Eric Jia, Scott Yamamoto\n",
    "\n",
    "# Overview\n",
    "\n",
    "This is the first of two notebooks and contains the code used to pre-process the MIMIC-3 data for model training. The second notebook uses the processed data from the end of this one in order to compare different models' performances."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e2bda50-0d9d-4333-a9b8-e826f6058a54",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c24ae579-d3de-4109-aa42-6da3dfac5a4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in ./.venv/lib/python3.12/site-packages (25.0.1)\n",
      "Requirement already satisfied: pyarrow in ./.venv/lib/python3.12/site-packages (19.0.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade pip\n",
    "!pip install pyarrow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "986e9476-34f9-4349-9b43-2964dd8dc0d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75c4536a-668b-49e3-b2f3-d5b5e363c20b",
   "metadata": {},
   "source": [
    "# Load CSV files with only necessary columns\n",
    "\n",
    "We use the data from 6 different tables within MIMIC-3. To access these files, you must first register as a user and complete the mandatory CITI training and Data Use Agreement here: https://physionet.org/content/mimiciii/1.4/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "de29045c-33c7-4479-af58-0f53cd8e2f28",
   "metadata": {},
   "outputs": [],
   "source": [
    "labevents_df = pd.read_csv(\n",
    "    \"/Users/ericjia/Downloads/MIMIC-3 DAta/LABEVENTS.csv\",\n",
    "    usecols=[\"SUBJECT_ID\", \"HADM_ID\", \"ITEMID\", \"VALUENUM\"]\n",
    ")\n",
    "\n",
    "chartevents_df = pd.read_csv(\n",
    "    \"/Users/ericjia/Downloads/MIMIC-3 DAta/CHARTEVENTS.csv\",\n",
    "    usecols=[\"HADM_ID\", \"ITEMID\", \"VALUENUM\"]\n",
    ")\n",
    "\n",
    "outputevents_df = pd.read_csv(\n",
    "    \"/Users/ericjia/Downloads/MIMIC-3 DAta/OUTPUTEVENTS.csv\",\n",
    "    usecols=[\"HADM_ID\", \"ITEMID\", \"VALUE\"]\n",
    ")\n",
    "\n",
    "patients_df = pd.read_csv(\n",
    "    \"/Users/ericjia/Downloads/MIMIC-3 DAta/PATIENTS.csv\",\n",
    "    usecols=[\"SUBJECT_ID\", \"DOB\", \"GENDER\"]\n",
    ")\n",
    "\n",
    "admissions_df = pd.read_csv(\n",
    "    \"/Users/ericjia/Downloads/MIMIC-3 DAta/ADMISSIONS.csv\",\n",
    "    usecols=[\"HADM_ID\", \"ADMITTIME\", \"DISCHTIME\", \"DEATHTIME\", \"MARITAL_STATUS\", \"INSURANCE\"]\n",
    ")\n",
    "\n",
    "icustays_df = pd.read_csv(\n",
    "    \"/Users/ericjia/Downloads/MIMIC-3 DAta/ICUSTAYS.csv\",\n",
    "    usecols=[\"HADM_ID\", \"FIRST_CAREUNIT\", \"LAST_CAREUNIT\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23f3a66b-f330-40b6-8e14-734dd5e0a302",
   "metadata": {},
   "source": [
    "# Convert datatypes for memory efficiency & merges\n",
    "\n",
    "Convert the datatypes for memory efficiency. Additionally, convert times to datetime format to standardize time series data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2370b667-3b93-4171-9291-4c8220cabd48",
   "metadata": {},
   "outputs": [],
   "source": [
    "admissions_df[\"ADMITTIME\"] = pd.to_datetime(admissions_df[\"ADMITTIME\"])\n",
    "admissions_df[\"DISCHTIME\"] = pd.to_datetime(admissions_df[\"DISCHTIME\"])\n",
    "admissions_df[\"DEATHTIME\"] = pd.to_datetime(admissions_df[\"DEATHTIME\"])\n",
    "patients_df[\"DOB\"] = pd.to_datetime(patients_df[\"DOB\"])\n",
    "\n",
    "labevents_df[\"SUBJECT_ID\"] = labevents_df[\"SUBJECT_ID\"].astype(\"Int64\")\n",
    "labevents_df[\"HADM_ID\"] = labevents_df[\"HADM_ID\"].astype(\"Int64\")\n",
    "chartevents_df[\"HADM_ID\"] = chartevents_df[\"HADM_ID\"].astype(\"Int64\")\n",
    "outputevents_df[\"HADM_ID\"] = outputevents_df[\"HADM_ID\"].astype(\"Int64\")\n",
    "patients_df[\"SUBJECT_ID\"] = patients_df[\"SUBJECT_ID\"].astype(\"Int64\")\n",
    "admissions_df[\"HADM_ID\"] = admissions_df[\"HADM_ID\"].astype(\"Int64\")\n",
    "icustays_df[\"HADM_ID\"] = icustays_df[\"HADM_ID\"].astype(\"Int64\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51ccfdcb-6846-4ce1-8767-79ee34cf3f68",
   "metadata": {},
   "source": [
    "# Define helper functions and aggregate the tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "92a0d28f-1914-4024-9935-f229287da822",
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate_lab(df, itemid, prefix):\n",
    "    subset = df[df[\"ITEMID\"] == itemid].copy()\n",
    "    aggs = subset.groupby([\"SUBJECT_ID\", \"HADM_ID\"])[\"VALUENUM\"].agg([\"min\",\"max\",\"mean\"])\n",
    "    aggs.rename(columns={\"min\": f\"{prefix}_MIN\", \"max\": f\"{prefix}_MAX\", \"mean\": f\"{prefix}_MEAN\"}, inplace=True)\n",
    "    return aggs.reset_index()\n",
    "\n",
    "def aggregate_chart(df, itemids, prefix, valid_min=None, valid_max=None):\n",
    "    subset = df[df[\"ITEMID\"].isin(itemids)].copy()\n",
    "    if valid_min is not None and valid_max is not None:\n",
    "        subset = subset[subset[\"VALUENUM\"].between(valid_min, valid_max)]\n",
    "    aggs = subset.groupby(\"HADM_ID\")[\"VALUENUM\"].agg([\"min\",\"max\",\"mean\"])\n",
    "    aggs.rename(columns={\"min\": f\"{prefix}_MIN\", \"max\": f\"{prefix}_MAX\", \"mean\": f\"{prefix}_MEAN\"}, inplace=True)\n",
    "    return aggs.reset_index()\n",
    "\n",
    "def aggregate_output(df, itemids):\n",
    "    subset = df[df[\"ITEMID\"].isin(itemids)].copy()\n",
    "    aggs = subset.groupby(\"HADM_ID\")[\"VALUE\"].agg([\"min\",\"max\",\"mean\"])\n",
    "    aggs.rename(columns={\"min\": \"URINE_MIN\", \"max\": \"URINE_MAX\", \"mean\": \"URINE_MEAN\"}, inplace=True)\n",
    "    return aggs.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "baf78dd8-11ae-48a3-8313-0da79db73f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# aggregate the data from LABEVENTS.csv\n",
    "\n",
    "lab_urea = aggregate_lab(labevents_df, 51006, \"UREA_N\")\n",
    "lab_platelets = aggregate_lab(labevents_df, 51265, \"PLATELETS\")\n",
    "lab_mag = aggregate_lab(labevents_df, 50960, \"MAGNESIUM\")\n",
    "lab_albumin = aggregate_lab(labevents_df, 50862, \"ALBUMIN\")\n",
    "lab_calcium = aggregate_lab(labevents_df, 50893, \"CALCIUM\")\n",
    "\n",
    "lab_aggs = (\n",
    "    lab_urea\n",
    "    .merge(lab_platelets, on=[\"SUBJECT_ID\",\"HADM_ID\"], how=\"outer\")\n",
    "    .merge(lab_mag, on=[\"SUBJECT_ID\",\"HADM_ID\"], how=\"outer\")\n",
    "    .merge(lab_albumin, on=[\"SUBJECT_ID\",\"HADM_ID\"], how=\"outer\")\n",
    "    .merge(lab_calcium, on=[\"SUBJECT_ID\",\"HADM_ID\"], how=\"outer\")\n",
    ")\n",
    "\n",
    "lab_aggs.to_csv(\"/Users/ericjia/Downloads/lab_aggs.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f6bfb18f-8a81-41ee-bcfa-5738d0c644ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# aggregate the data from CHARTEVENTS.csv\n",
    "\n",
    "resp_itemids = [615, 618, 220210, 224690]\n",
    "resp_df = aggregate_chart(chartevents_df, resp_itemids, \"RESP_RATE\", 0, 70)\n",
    "\n",
    "hr_itemids = [211, 220045]\n",
    "hr_df = aggregate_chart(chartevents_df, hr_itemids, \"HR\", 0, 300)\n",
    "\n",
    "glucose_itemids = [807, 811, 1529, 3745, 3744, 225664, 220621, 226537]\n",
    "glucose_df = aggregate_chart(chartevents_df, glucose_itemids, \"GLUCOSE\", 0, 10000)\n",
    "\n",
    "sysbp_itemids = [51, 442, 455, 6701, 220179, 220050]\n",
    "sysbp_df = aggregate_chart(chartevents_df, sysbp_itemids, \"SYSBP\", 0, 400)\n",
    "\n",
    "diasbp_itemids = [8368, 8440, 8441, 8555, 220180, 220051]\n",
    "diasbp_df = aggregate_chart(chartevents_df, diasbp_itemids, \"DIASBP\", 0, 300)\n",
    "\n",
    "# Merge all tables\n",
    "chart_aggs = (\n",
    "    resp_df\n",
    "    .merge(hr_df, on=\"HADM_ID\", how=\"outer\")\n",
    "    .merge(glucose_df, on=\"HADM_ID\", how=\"outer\")\n",
    "    .merge(sysbp_df, on=\"HADM_ID\", how=\"outer\")\n",
    "    .merge(diasbp_df, on=\"HADM_ID\", how=\"outer\")\n",
    ")\n",
    "\n",
    "chart_aggs.to_csv(\"/Users/ericjia/Downloads/chart_aggs.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "f245ffe5-9995-4fb0-91b5-e6ba09c6cca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# aggregate the data from OUTPUTEVENTS.csv\n",
    "\n",
    "output_agg = aggregate_output(outputevents_df, [40055, 226559])\n",
    "\n",
    "# meerge all tables Everything (no SAPSII/SOFA)\n",
    "merged_df = (\n",
    "    lab_aggs\n",
    "    .merge(output_agg, on=\"HADM_ID\", how=\"inner\")\n",
    "    .merge(patients_df, on=\"SUBJECT_ID\", how=\"inner\")\n",
    "    .merge(admissions_df, on=\"HADM_ID\", how=\"inner\")\n",
    "    .merge(chart_aggs, on=\"HADM_ID\", how=\"inner\")\n",
    "    .merge(icustays_df, on=\"HADM_ID\", how=\"inner\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "d474899e-6149-40b6-aaa1-3a19f8f6bf76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final shape: (44622, 43)\n",
      "   SUBJECT_ID  HADM_ID           ADMITTIME           DISCHTIME  \\\n",
      "0           3   145834 2101-10-20 19:08:00 2101-10-31 13:58:00   \n",
      "1           6   107064 2175-05-30 07:15:00 2175-06-15 16:00:00   \n",
      "2           9   150750 2149-11-09 13:06:00 2149-11-14 10:15:00   \n",
      "3          12   112213 2104-08-07 10:15:00 2104-08-20 02:57:00   \n",
      "4          13   143045 2167-01-08 18:43:00 2167-01-15 15:15:00   \n",
      "\n",
      "            DEATHTIME FIRST_CAREUNIT LAST_CAREUNIT GENDER MARITAL_STATUS  \\\n",
      "0                 NaT           MICU          MICU      M        MARRIED   \n",
      "1                 NaT           SICU          SICU      F        MARRIED   \n",
      "2 2149-11-14 10:15:00           MICU          MICU      M            NaN   \n",
      "3 2104-08-20 02:57:00           SICU          SICU      M        MARRIED   \n",
      "4                 NaT            CCU          CSRU      F            NaN   \n",
      "\n",
      "  INSURANCE  ...  SYSBP_MEAN  DIASBP_MIN  DIASBP_MAX  DIASBP_MEAN  \\\n",
      "0  Medicare  ...  116.767045         0.0       103.0    58.308571   \n",
      "1  Medicare  ...  153.750000        40.0        88.0    60.010417   \n",
      "2  Medicaid  ...  149.716495        47.0       194.0    76.731959   \n",
      "3  Medicare  ...  152.032558        45.0       111.0    72.409302   \n",
      "4  Medicaid  ...  132.271930        39.0        90.0    65.219298   \n",
      "\n",
      "   GLUCOSE_MIN  GLUCOSE_MAX  GLUCOSE_MEAN  URINE_MIN  URINE_MEAN  URINE_MAX  \n",
      "0         67.0        306.0    152.096774        5.0  142.943396      600.0  \n",
      "1         66.0        254.0    118.789474       20.0   80.689655      200.0  \n",
      "2         92.0        225.0    153.137931       10.0  147.952381     1100.0  \n",
      "3         79.0        191.0    139.729730       30.0  171.735294      540.0  \n",
      "4         81.0        239.0    158.981481       30.0   98.214286      260.0  \n",
      "\n",
      "[5 rows x 43 columns]\n"
     ]
    }
   ],
   "source": [
    "# select & rename columns\n",
    "\n",
    "final_columns = [\n",
    "    \"SUBJECT_ID\", \"HADM_ID\", \"ADMITTIME\", \"DISCHTIME\", \"DEATHTIME\",\n",
    "    \"FIRST_CAREUNIT\", \"LAST_CAREUNIT\", \"GENDER\", \"MARITAL_STATUS\", \"INSURANCE\",\n",
    "    \"UREA_N_MIN\", \"UREA_N_MAX\", \"UREA_N_MEAN\",\n",
    "    \"PLATELETS_MIN\", \"PLATELETS_MAX\", \"PLATELETS_MEAN\",\n",
    "    \"MAGNESIUM_MIN\", \"MAGNESIUM_MAX\", \"MAGNESIUM_MEAN\",\n",
    "    \"ALBUMIN_MIN\", \"ALBUMIN_MAX\", \"ALBUMIN_MEAN\",\n",
    "    \"CALCIUM_MIN\", \"CALCIUM_MAX\", \"CALCIUM_MEAN\",\n",
    "    \"RESP_RATE_MIN\", \"RESP_RATE_MAX\", \"RESP_RATE_MEAN\",\n",
    "    \"HR_MIN\", \"HR_MAX\", \"HR_MEAN\",\n",
    "    \"SYSBP_MIN\", \"SYSBP_MAX\", \"SYSBP_MEAN\",\n",
    "    \"DIASBP_MIN\", \"DIASBP_MAX\", \"DIASBP_MEAN\",\n",
    "    \"GLUCOSE_MIN\", \"GLUCOSE_MAX\", \"GLUCOSE_MEAN\",\n",
    "    \"URINE_MIN\", \"URINE_MEAN\", \"URINE_MAX\"\n",
    "]\n",
    "\n",
    "# keep only existing columns\n",
    "existing_cols = [c for c in final_columns if c in merged_df.columns]\n",
    "final_df = merged_df[existing_cols].sort_values([\"SUBJECT_ID\",\"ADMITTIME\"])\n",
    "print(\"Final shape:\", final_df.shape)\n",
    "print(final_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d894295-1dc4-4a7f-8494-cc66eddd9eeb",
   "metadata": {},
   "source": [
    "# Determine whether each pt is re-admitted within 30 days\n",
    "\n",
    "This section mainly involves determining whether each patient was readmitted within 30 days."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "458555e9-d3f2-46ea-b2ab-5940e0260d2a",
   "metadata": {},
   "source": [
    "Basic exploratory data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "cc1e0fb6-b265-40b0-8950-d92ff38e6138",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      UREA_N_MIN  UREA_N_MEAN  UREA_N_MAX\n",
      "mean   16.654032    25.931473   38.008854\n",
      "std    13.610900    18.676178   29.019086 \n",
      "\n",
      "      MAGNESIUM_MAX  ALBUMIN_MIN  CALCIUM_MIN\n",
      "mean       2.437725     2.933336     7.776259\n",
      "std        0.924376     0.753183     0.841790 \n",
      "\n",
      "      RESP_RATE_MIN  RESP_RATE_MEAN  RESP_RATE_MAX\n",
      "mean       9.123511       19.150351      31.668871\n",
      "std        5.030956        3.583524       8.711681 \n",
      "\n",
      "      GLUCOSE_MIN  GLUCOSE_MEAN  GLUCOSE_MAX\n",
      "mean    90.588721    137.149771   217.015159\n",
      "std     31.211948     35.664115   127.363413 \n",
      "\n",
      "         HR_MIN    HR_MEAN      HR_MAX\n",
      "mean  61.961123  85.253221  114.401428\n",
      "std   18.930170  13.492709   24.599291 \n",
      "\n",
      "      SYSBP_MIN  SYSBP_MEAN   SYSBP_MAX\n",
      "mean  75.182391  120.359561  162.839337\n",
      "std   32.549534   15.938392   28.158213 \n",
      "\n",
      "      DIASBP_MIN  DIASBP_MEAN  DIASBP_MAX\n",
      "mean   34.506338    60.406628   96.555374\n",
      "std    16.139765     9.959304   26.208114 \n",
      "\n",
      "      URINE_MIN  URINE_MEAN     URINE_MAX\n",
      "mean  29.996947  131.179304    638.868149\n",
      "std   68.278302  610.686787  21873.807335 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(final_df[['UREA_N_MIN', 'UREA_N_MEAN', 'UREA_N_MAX']].describe().loc[['mean', 'std']], '\\n')\n",
    "print(final_df[['MAGNESIUM_MAX', 'ALBUMIN_MIN', 'CALCIUM_MIN']].describe().loc[['mean', 'std']], '\\n')\n",
    "print(final_df[['RESP_RATE_MIN', 'RESP_RATE_MEAN', 'RESP_RATE_MAX']].describe().loc[['mean', 'std']], '\\n')\n",
    "print(final_df[['GLUCOSE_MIN', 'GLUCOSE_MEAN', 'GLUCOSE_MAX']].describe().loc[['mean', 'std']], '\\n')\n",
    "print(final_df[['HR_MIN', 'HR_MEAN', 'HR_MAX']].describe().loc[['mean', 'std']], '\\n')\n",
    "print(final_df[['SYSBP_MIN', 'SYSBP_MEAN', 'SYSBP_MAX']].describe().loc[['mean', 'std']], '\\n')\n",
    "print(final_df[['DIASBP_MIN', 'DIASBP_MEAN', 'DIASBP_MAX']].describe().loc[['mean', 'std']], '\\n')\n",
    "print(final_df[['URINE_MIN', 'URINE_MEAN', 'URINE_MAX']].describe().loc[['mean', 'std']], '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "8032f10e-94ab-406e-9369-6e8dffc720e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(44622, 46)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df[\"ADMITTIME\"] = pd.to_datetime(final_df[\"ADMITTIME\"])\n",
    "final_df[\"DISCHTIME\"] = pd.to_datetime(final_df[\"DISCHTIME\"])\n",
    "\n",
    "# sort by SUBJECT_ID and ADMITTIME to ensure chronological order\n",
    "final_df = final_df.sort_values(by=[\"SUBJECT_ID\", \"ADMITTIME\"])\n",
    "\n",
    "# initialize new columns\n",
    "final_df[\"READMIT_DT\"] = 0.0\n",
    "final_df[\"NEXT_READMIT_DT\"] = 0.0\n",
    "final_df[\"READMIT_LAST_CAREUNIT\"] = None\n",
    "\n",
    "# calculate time delta for readmissions\n",
    "for idx in range(1, final_df.shape[0]):\n",
    "    if final_df.iloc[idx][\"SUBJECT_ID\"] == final_df.iloc[idx - 1][\"SUBJECT_ID\"]:\n",
    "        prev_disch = final_df.iloc[idx - 1][\"DISCHTIME\"]\n",
    "        curr_adm = final_df.iloc[idx][\"ADMITTIME\"]\n",
    "\n",
    "        # convert to hours\n",
    "        dt = (curr_adm - prev_disch).total_seconds() / 3600  \n",
    "        dt_hrs_calc = round(dt, 2)\n",
    "\n",
    "        # assign values\n",
    "        final_df.at[idx, \"READMIT_DT\"] = dt_hrs_calc\n",
    "        final_df.at[idx - 1, \"NEXT_READMIT_DT\"] = dt_hrs_calc\n",
    "        final_df.at[idx, \"READMIT_LAST_CAREUNIT\"] = final_df.iloc[idx - 1][\"LAST_CAREUNIT\"]\n",
    "\n",
    "final_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "cf8daf3b-b3cc-447a-b471-111972056d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = final_df.drop(columns=['URINE_MIN', 'URINE_MEAN', 'URINE_MAX'], errors='ignore')\n",
    "\n",
    "# remove rows where READMIT_DT is negative\n",
    "final_df = final_df[final_df[\"READMIT_DT\"] >= 0]\n",
    "\n",
    "# remove cases where the patient died during their stay\n",
    "final_df = final_df[final_df[\"DEATHTIME\"].isna()]\n",
    "\n",
    "# drop the DEATHTIME column to prevent unnecessary data loss when dropping NaNs\n",
    "final_df = final_df.drop(columns=['DEATHTIME'], errors='ignore')\n",
    "\n",
    "# drop rows with NaNs in all columns except the last column\n",
    "final_df = final_df.dropna(subset=final_df.columns[:-1]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "041bc089-9380-46f6-b59a-50dad62e983e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20948, 42)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "01e0ea9d-a932-4a9b-857f-3ee12fdf79f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value counts:\n",
      "FUTURE_READMIT\n",
      "No     18184\n",
      "Yes     2764\n",
      "Name: count, dtype: int64 \n",
      "\n",
      "Value proportions:\n",
      "FUTURE_READMIT\n",
      "No     0.868054\n",
      "Yes    0.131946\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# define the threshold in hours (30 days)\n",
    "threshold = 30 * 24  \n",
    "\n",
    "# initialize FUTURE_READMIT column\n",
    "final_df[\"FUTURE_READMIT\"] = np.where(\n",
    "    final_df[\"NEXT_READMIT_DT\"] == 0.0, \"No\",\n",
    "    np.where(final_df[\"NEXT_READMIT_DT\"] <= threshold, \"Yes\", \"No\")\n",
    ")\n",
    "\n",
    "# display value counts and proportions\n",
    "print(\"Value counts:\")\n",
    "print(final_df[\"FUTURE_READMIT\"].value_counts(), \"\\n\")\n",
    "\n",
    "print(\"Value proportions:\")\n",
    "print(final_df[\"FUTURE_READMIT\"].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "da8e93b9-7fe0-458b-ae0f-af194706a6a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# aggregate the data from NOTEEVENTS.csv\n",
    "noteevents_df = pd.read_csv('/Users/ericjia/Downloads/MIMIC-3 DAta/NOTEEVENTS.csv')\n",
    "\n",
    "noteevents_unique = noteevents_df.groupby(\"HADM_ID\")[\"TEXT\"].first().reset_index()\n",
    "\n",
    "# merge with final_df on HADM_ID to get the discharge summaries\n",
    "final_df = final_df.merge(noteevents_unique, on=\"HADM_ID\", how=\"left\")\n",
    "final_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f9b4f2f5-0f66-4b8a-8829-b79eb17f1773",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.to_csv(\"/Users/ericjia/Downloads/543 project/full_final_df.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
